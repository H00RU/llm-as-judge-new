# æ²»æœ¬ä¿®å¤å®æ–½æŒ‡å—

**ç›®æ ‡**: ç”¨æ”¹è¿›çš„ Prompt æ›¿æ¢æ—§çš„ï¼Œè®© Qwen çœŸæ­£å­¦ä¼šç”Ÿæˆæ­£ç¡®çš„ä»£ç 

**é¢„æœŸç»“æœ**:
- çŸ­æœŸï¼ˆStep 1-2ï¼‰ï¼šç­¾åå’Œ Operator é”™è¯¯å‡å°‘
- ä¸­æœŸï¼ˆStep 3-5ï¼‰ï¼šç†è§£çº¦æŸçš„é€»è¾‘
- é•¿æœŸï¼ˆStep 6-10ï¼‰ï¼šæ¨¡å‹æœ‰æ•ˆå­¦ä¹ ï¼Œå¤±è´¥ç‡æ˜¾è‘—ä¸‹é™

---

## ç¬¬1æ­¥ï¼šå¤‡ä»½åŸå§‹ä»£ç 

```bash
cp /root/llm-as-judge-new/src/rl_workflow_generator.py \
   /root/llm-as-judge-new/src/rl_workflow_generator.py.backup
```

---

## ç¬¬2æ­¥ï¼šä¿®æ”¹ `_build_generation_prompt()` æ–¹æ³•

æ‰“å¼€æ–‡ä»¶ï¼š
```bash
vim /root/llm-as-judge-new/src/rl_workflow_generator.py
```

æ‰¾åˆ° `_build_generation_prompt()` æ–¹æ³•ï¼ˆç¬¬ 113 è¡Œï¼‰ã€‚

**æ›¿æ¢å†…å®¹**ï¼š

ä»ï¼š
```python
def _build_generation_prompt(self, problem: str, problem_type: str) -> str:
    """æ„å»ºæç¤ºè¯ï¼Œæ˜ç¡®ç®—å­ API"""

    prompt = f"""Generate a Python Workflow class. Follow the exact template and API signatures.

CRITICAL: Only use operators listed below with their EXACT parameters!
...
"""
```

æ”¹ä¸ºä¸‹é¢çš„æ–°å®ç°ã€‚ä¸ºäº†ç®€æ´ï¼Œæˆ‘æä¾›ä¸€ä¸ªä»£ç æ¡†æ¶ï¼š

```python
def _build_generation_prompt(self, problem: str, problem_type: str) -> str:
    """æ„å»ºæ”¹è¿›çš„æç¤ºè¯ - å¼ºåˆ¶æ€§ã€æ•™è‚²æ€§ã€å®Œæ•´ç¤ºä¾‹"""

    prompt = """Generate a Python Workflow class that solves problems using AFlow operators.

================================================================================
âš ï¸ CRITICAL DESIGN PRINCIPLE - READ THIS FIRST
================================================================================

The Workflow.__call__ method signature is FIXED and MUST NOT be changed:

    async def __call__(self, problem: str, entry_point: str = None)

WHY this signature is fixed:
  - Provides a UNIFIED interface for all problem types
  - Different problem types are distinguished by CONTENT, not by parameters
  - Allows the system to call the Workflow consistently

WHAT HAPPENS if you add extra parameters (WRONG):
  - ERROR: TypeError: missing positional arguments
  - System cannot execute your workflow
  - Workflow crashes with error
  - EXAMPLE OF WRONG SIGNATURE:
      async def __call__(self, problem, code, entry_point=None, test=None):  # âŒ WRONG!
  - EXAMPLE OF CORRECT SIGNATURE:
      async def __call__(self, problem: str, entry_point: str = None):  # âœ… CORRECT!

================================================================================
OPERATORS - Use EXACTLY these signatures
================================================================================

1. AnswerGenerate(llm) - Generate reasoning + answer
   await self.answer_generate(input=str) â†’ {'thought': str, 'answer': str}
   IMPORTANT: NO 'instruction' parameter!

2. Programmer(llm) - Generate and execute Python code
   await self.programmer(problem=str, analysis=str) â†’ {'code': str, 'output': str}

3. Test(llm) - Test code with test cases (CODE ONLY)
   await self.test(problem=str, solution=str, entry_point=str) â†’ {'result': bool, 'solution': str}
   CRITICAL: Use ONLY for CODE problems!
   CRITICAL: entry_point is REQUIRED!

4. Review(llm) - Review solution
   await self.review(problem=str, solution=str) â†’ {'review_result': bool, 'feedback': str}

5. Revise(llm) - Revise based on feedback
   await self.revise(problem=str, solution=str, feedback=str) â†’ {'solution': str}

6. Custom(llm) - Custom task
   await self.custom(input=str, instruction=str) â†’ {'response': str}

7. ScEnsemble(llm) - Ensemble voting
   await self.sc_ensemble(solutions=list, problem=str) â†’ {'response': str}

================================================================================
PROBLEM-TYPE SPECIFIC RULES - MUST FOLLOW
================================================================================
"""

    # Add problem-type specific rules
    if problem_type == "math":
        prompt += """
ğŸ“Š MATH PROBLEMS
================================================================================

MUST DO:
  âœ… Use AnswerGenerate to generate reasoning and answer
  âœ… Optionally use Review to verify
  âœ… Optionally use Revise to improve

MUST NOT DO (VIOLATION = ERROR + PENALTY):
  âŒ Use Test operator
     WHY: Math problems have NO test cases. Test will crash.
     WHAT_HAPPENS: TypeError - 'NoneType' object is not subscriptable
     PENALTY: -5.0 reward

  âŒ Use Programmer operator
     WHY: Math is not code. This is inefficient and wrong.
     PENALTY: -5.0 reward

  âŒ Use entry_point parameter
     WHY: Math doesn't have entry_point
     PENALTY: Parameter error

âœ… CORRECT MATH WORKFLOW:
    async def __call__(self, problem: str, entry_point: str = None):
        answer_result = await self.answer_generate(input=problem)
        answer = answer_result.get('answer', '')

        review_result = await self.review(problem=problem, solution=answer)
        if not review_result.get('review_result', True):
            revise_result = await self.revise(problem=problem, solution=answer,
                                              feedback=review_result.get('feedback', ''))
            answer = revise_result.get('solution', answer)

        return answer, self.llm.get_usage_summary()["total_cost"]

âŒ WRONG MATH WORKFLOW:
    async def __call__(self, problem, code, entry_point=None, test=None):  # âŒ Wrong signature!
        code = await self.programmer(problem=problem)  # âŒ Wrong operator!
        result = await self.test(problem=problem, solution=code)  # âŒ Wrong operator!
        return code, cost

================================================================================
"""

    elif problem_type == "code":
        prompt += """
ğŸ’» CODE PROBLEMS
================================================================================

CRITICAL: entry_point is ALWAYS provided for code problems.
Use it in Test operator: await self.test(..., entry_point=entry_point)

MUST DO:
  âœ… Use Programmer to generate Python code
  âœ… Use Test to verify code with test cases
  âœ… Test MUST use entry_point

MUST NOT DO (VIOLATION = ERROR + PENALTY):
  âŒ Skip Test operator
     WHY: Code must be verified! Otherwise wrong answers.
     PENALTY: -10.0 reward

  âŒ Call Test without entry_point
     WHY: Test needs entry_point to find test cases
     WHAT_HAPPENS: TypeError - entry_point not found
     PENALTY: -10.0 reward

  âŒ Add extra parameters to __call__
     WHY: Signature is fixed for all problem types
     PENALTY: Workflow crashes

âœ… CORRECT CODE WORKFLOW:
    async def __call__(self, problem: str, entry_point: str = None):
        prog_result = await self.programmer(problem=problem, analysis='')
        code = prog_result.get('code', '')

        test_result = await self.test(problem=problem, solution=code,
                                      entry_point=entry_point)  # âœ… Use entry_point!
        if test_result.get('result', False):
            return code, self.llm.get_usage_summary()["total_cost"]

        # Revise if test failed
        review_result = await self.review(problem=problem, solution=code)
        revise_result = await self.revise(problem=problem, solution=code,
                                         feedback=review_result.get('feedback', ''))
        return revise_result.get('solution', code), self.llm.get_usage_summary()["total_cost"]

âŒ WRONG CODE WORKFLOW (missing Test):
    async def __call__(self, problem: str, entry_point: str = None):
        code = await self.programmer(problem=problem)  # Missing Test!
        return code, cost

================================================================================
"""

    elif problem_type == "qa":
        prompt += """
ğŸ“‹ QA PROBLEMS
================================================================================

MUST DO:
  âœ… Use AnswerGenerate to generate reasoning and answer
  âœ… Optionally use Review to validate
  âœ… Optionally use Revise to improve

MUST NOT DO (VIOLATION = ERROR + PENALTY):
  âŒ Use Test operator
     WHY: QA problems have NO test cases
     WHAT_HAPPENS: TypeError - 'NoneType' object is not subscriptable
     PENALTY: -5.0 reward

  âŒ Use Programmer operator
     WHY: QA is text-based, not code. This is inefficient.
     PENALTY: -5.0 reward

âœ… CORRECT QA WORKFLOW:
    async def __call__(self, problem: str, entry_point: str = None):
        answer_result = await self.answer_generate(input=problem)
        answer = answer_result.get('answer', '')

        review_result = await self.review(problem=problem, solution=answer)
        if not review_result.get('review_result', True):
            revise_result = await self.revise(problem=problem, solution=answer,
                                             feedback=review_result.get('feedback', ''))
            answer = revise_result.get('solution', answer)

        return answer, self.llm.get_usage_summary()["total_cost"]

================================================================================
"""

    # Common rules
    prompt += """
================================================================================
GENERAL RULES (ALL WORKFLOWS)
================================================================================

1. SIGNATURE: async def __call__(self, problem: str, entry_point: str = None)
   - NEVER add extra parameters
   - NEVER change parameter names or types

2. RETURN: (solution_string, cost_float)
   - return answer, self.llm.get_usage_summary()["total_cost"]

3. Initialize variables BEFORE if-blocks
   - answer = ''; if condition: answer = ...
   - NOT: if condition: answer = ...; return answer

4. Always use await for operator calls
   - result = await self.operator_name(...)

5. Check return values are dicts before .get()
   - value = result.get('key', default)

================================================================================
TEMPLATE (Complete __call__ method only)
================================================================================

import workspace.{problem_type}.workflows.template.operator as operator
from scripts.async_llm import create_llm_instance
from scripts.evaluator import DatasetType

class Workflow:
    def __init__(self, name: str, llm_config, dataset: DatasetType):
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)
        # Initialize operators you need:
        # self.answer_generate = operator.AnswerGenerate(self.llm)
        # self.programmer = operator.Programmer(self.llm)
        # self.test = operator.Test(self.llm)
        # self.review = operator.Review(self.llm)
        # self.revise = operator.Revise(self.llm)

    async def __call__(self, problem: str, entry_point: str = None):
        # Follow the {problem_type} problem rules above
        # Return: (solution_string, cost_float)
        pass
"""

    return prompt
```

---

## ç¬¬3æ­¥ï¼šæµ‹è¯•æ–° Prompt

ç”Ÿæˆä¸€ä¸ªæ ·æœ¬æ¥éªŒè¯æ–° Prompt æ˜¯å¦å·¥ä½œï¼š

```bash
python3 << 'EOF'
from src.rl_workflow_generator import RLWorkflowGenerator

generator = RLWorkflowGenerator(
    base_model="/root/llm-as-judge-new/models"
)

# æµ‹è¯• MATH Prompt
math_prompt = generator._build_generation_prompt(
    problem="A problem",
    problem_type="math"
)

print("MATH Prompt length:", len(math_prompt))
print("Contains 'MUST NOT':", "MUST NOT" in math_prompt)
print("Contains correct example:", "âœ… CORRECT MATH WORKFLOW" in math_prompt)
print("Contains wrong example:", "âŒ WRONG MATH WORKFLOW" in math_prompt)

# æµ‹è¯• CODE Prompt
code_prompt = generator._build_generation_prompt(
    problem="A problem",
    problem_type="code"
)

print("\nCODE Prompt length:", len(code_prompt))
print("Contains 'entry_point is ALWAYS provided':", "entry_point is ALWAYS provided" in code_prompt)

# æµ‹è¯• QA Prompt
qa_prompt = generator._build_generation_prompt(
    problem="A problem",
    problem_type="qa"
)

print("\nQA Prompt length:", len(qa_prompt))
print("All Prompts generated successfully!")
EOF
```

---

## ç¬¬4æ­¥ï¼šé‡æ–°å¯åŠ¨è®­ç»ƒ

### 4a. æ€æ­»å½“å‰è®­ç»ƒ

```bash
kill 42317
```

### 4b. æ£€æŸ¥è®­ç»ƒæ—¥å¿—çš„æœ€åéƒ¨åˆ†

```bash
tail -50 /root/llm-as-judge-new/nohup_training.log
```

### 4c. é‡æ–°å¯åŠ¨è®­ç»ƒ

```bash
cd /root/llm-as-judge-new
nohup python train.py --config config/minimal_training.yaml > nohup_training.log 2>&1 &
echo $! > .minimal_training_pid
tail -f nohup_training.log
```

---

## é¢„æœŸè§‚å¯Ÿ

### ç«‹å³ï¼ˆStep 1-2ï¼‰

```
æ—§ Prompt ä¸‹ï¼ˆå·²å®Œæˆï¼‰:
  âœ… FallbackæˆåŠŸ: 9/9 (100%)
  âœ… æ­£ç¡®è¯„åˆ†: 1/9 (11%)
  âœ… å¤±è´¥è¯„åˆ†: 8/9 (89%) å¹³å‡ -2.75/10.0

æ–° Prompt ä¸‹ï¼ˆé¢„æœŸï¼‰:
  âœ… ç­¾åé”™è¯¯å‡å°‘ï¼ˆæ›´å¼ºçš„å¼ºåˆ¶è¯­è¨€ï¼‰
  âœ… Operator é”™è¯¯å‡å°‘ï¼ˆæ›´æ¸…æ™°çš„çº¦æŸï¼‰
  âœ… Fallback éœ€æ±‚å‡å°‘
```

### ä¸­æœŸï¼ˆStep 3-5ï¼‰

```
é¢„æœŸæ”¹è¿›:
  - å¦‚æœæ”¹è¿›æœ‰æ•ˆï¼ŒFallback é¢‘ç‡åº”è¯¥é™ä½
  - é€šè¿‡ Fallback æ‰§è¡Œçš„å·¥ä½œæµæ¯”ä¾‹åº”è¯¥ä¸‹é™
  - GRPO å­¦ä¹ ä¿¡å·åº”è¯¥å˜å¼º
```

### é•¿æœŸï¼ˆStep 6-10ï¼‰

```
ç›®æ ‡çŠ¶æ€:
  - ç”Ÿæˆçš„ä»£ç è´¨é‡æ˜æ˜¾æé«˜
  - ä¸éœ€è¦ Fallback çš„å·¥ä½œæµå¢åŠ 
  - æ¨¡å‹çœŸæ­£å­¦åˆ°äº†çº¦æŸå’Œè®¾è®¡åŸåˆ™
```

---

## å¦‚ä½•ç›‘æ§æ”¹è¿›

```bash
# æŸ¥çœ‹æ–°ç”Ÿæˆçš„ä»£ç æ˜¯å¦æœ‰æ”¹è¿›
grep -E "async def __call__|TypeError|missing.*positional" nohup_training.log | tail -20

# ç»Ÿè®¡ Fallback æ¬¡æ•°
grep "ğŸ”„ æ‰§è¡ŒFallback" nohup_training.log | wc -l

# æŸ¥çœ‹è¯„åˆ†å˜åŒ–
grep "æ­£ç¡®æ€§è¯„åˆ†" nohup_training.log | tail -20
```

---

## æ€»ç»“

è¿™ä¸ªæ”¹è¿›é€šè¿‡ä»¥ä¸‹æ–¹å¼è®© Qwen çœŸæ­£å­¦ä¼šï¼š

1. **å¼ºåˆ¶æ€§è¯­è¨€** - MUST, MUST NOTï¼ˆä¸æ˜¯å»ºè®®ï¼‰
2. **æ•™è‚²æ€§å†…å®¹** - WHY, WHAT_HAPPENSï¼ˆä¸æ˜¯ä»…ä»…è§„åˆ™ï¼‰
3. **å®Œæ•´ç¤ºä¾‹** - æ­£ç¡®å’Œé”™è¯¯çš„ä»£ç ï¼ˆä¸æ˜¯æŠ½è±¡è¯´æ˜ï¼‰
4. **é€»è¾‘è§£é‡Š** - ä¸ºä»€ä¹ˆç­¾åè¦å›ºå®šï¼ˆè®¾è®¡åŸç†ï¼‰

è¿™æ · Qwen ä¼šé€æ­¥ç†è§£çº¦æŸçš„æœ¬è´¨ï¼Œè€Œä¸ä»…ä»…æ˜¯éµå®ˆè§„åˆ™ã€‚

---

*ç‰ˆæœ¬*: æ²»æœ¬å®æ–½æŒ‡å—
*æ—¶é—´*: 2025-12-01 16:52:00
