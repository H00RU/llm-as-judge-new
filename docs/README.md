# LLM-as-Judge: Mixed Training Baseline

<div align="center">

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.6+-ee4c2c.svg)](https://pytorch.org/)

*Mixed-domain GRPO training baseline on 6 diverse datasets*

[âš¡ Quick Start](#-quick-start) â€¢ [ğŸ“š Docs](#-documentation) â€¢ [ğŸ—ï¸ Architecture](#-architecture)

</div>

---

## ğŸ“– Overview

Baseline training framework for evaluating LLMs on **6 diverse datasets** with mixed-domain training:

- **Datasets**: GSM8K, MATH (math), SQuAD2.0, HotpotQA (QA), HumanEval, MBPP (code)
- **Data Strategy**: Train:Test = 5:1 (83.3%:16.7%), domain-balanced mixing (4:3:3)
- **Models**: Qwen2.5-7B, Qwen-3-8B (LoRA rank-64)
- **Algorithm**: GRPO (Group Relative Policy Optimization) online learning
- **Evaluation**: Per-dataset metrics on all 6 test sets

---

## âš¡ Quick Start

### 1ï¸âƒ£ Installation (5 min)

```bash
# Clone + setup environment
git clone <repo> && cd llm-as-judge
python -m venv venv && source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2ï¸âƒ£ Download & Process Data (10 min)

```bash
# Download 6 datasets from HuggingFace
python scripts/download_datasets.py

# Process with balanced mixing (Train:Test = 5:1)
python scripts/process_datasets.py
# Output: data/mixed/train_mixed.jsonl + test_mixed.jsonl
```

### 3ï¸âƒ£ Train (configurable duration)

```bash
# Full pipeline: download â†’ process â†’ train â†’ evaluate
./scripts/run_full_pipeline.sh --model qwen25-7b --device cuda:0

# Or individual steps
python train.py --model qwen25-7b --device cuda:0
```

### 4ï¸âƒ£ Evaluate Results

```bash
# Results auto-saved to results/evaluation/qwen25-7b_results.json
cat results/evaluation/qwen25-7b_results.json | jq '.datasets[] | {name: .dataset, accuracy: .metrics.accuracy}'
```

---

## ğŸ—ï¸ Architecture

```
Data Pipeline:
  download_datasets.py
     â†“
  process_datasets.py (Plan C mixing)
     â”œâ”€ 6 datasets â†’ 5:1 split (train:test)
     â”œâ”€ Domain intra-balance (50:50)
     â””â”€ Cross-domain 4:3:3 mix
     â†“
  data/mixed/{train,test}_mixed.jsonl
     â†“
Training Loop:
  train.py (GRPO)
     â”œâ”€ Base: Qwen2.5-7B or Qwen-3-8B
     â”œâ”€ LoRA: rank=64
     â””â”€ Optimize on train_mixed.jsonl
     â†“
  checkpoints/qwen25-7b/grpo_mixed/step_*/
     â†“
Evaluation:
  eval_6datasets.py
     â”œâ”€ Eval on data/test/{gsm8k,math,squad2,hotpotqa,humaneval,mbpp}_test.jsonl
     â””â”€ Save metrics to results/evaluation/
```

### Data Structure

```
data/
â”œâ”€â”€ mixed/
â”‚   â”œâ”€â”€ train_mixed.jsonl        â† For GRPO training (~160K samples)
â”‚   â”œâ”€â”€ test_mixed.jsonl         â† For final eval (mixed 4:3:3)
â”‚   â””â”€â”€ info.json                â† Mixing metadata
â””â”€â”€ test/
    â”œâ”€â”€ gsm8k_test.jsonl         â† Independent evals
    â”œâ”€â”€ math_test.jsonl
    â”œâ”€â”€ squad2_test.jsonl
    â”œâ”€â”€ hotpotqa_test.jsonl
    â”œâ”€â”€ humaneval_test.jsonl
    â”œâ”€â”€ mbpp_test.jsonl
    â””â”€â”€ test_index.json
```

---

## ğŸ“š Documentation

| Document | Purpose |
|----------|---------|
| **[SETUP.md](SETUP.md)** | Installation, dependencies, model download |
| **[DATA.md](DATA.md)** | Data mixing strategy, formats, statistics |
| **[TRAINING.md](TRAINING.md)** | Training configs, monitoring, troubleshooting |

---

## ğŸ”§ Key Features

### Data Processing (Plan C)
âœ… **5:1 Split**: Train:Test = 83.3%:16.7% (no validation set)
âœ… **Domain Balance**: Intra-domain 50:50, Inter-domain 4:3:3
âœ… **Small-data Handling**: HumanEval/MBPP resampled to match larger peers
âœ… **Clear Separation**: Train/Test fully isolated from raw data loading

### Training
âœ… **Multi-model**: Both Qwen2.5-7B and Qwen-3-8B supported
âœ… **LoRA Efficient**: Rank=64, trainable params only
âœ… **Online Learning**: GRPO without replay buffer
âœ… **Flexible Config**: All hyperparams in `config/training.yaml`

### Evaluation
âœ… **Per-dataset Metrics**: Accuracy for all 6 datasets
âœ… **Mixed Evaluation**: Overall performance on balanced mix
âœ… **Reproducible**: Deterministic splits and fixed seeds

---

## ğŸ“Š Expected Data Volumes

| Dataset | Domain | Train | Test |
|---------|--------|-------|------|
| GSM8K | math | 6.2K | 1.2K |
| MATH | math | 6.3K | 1.3K |
| SQuAD2.0 | qa | 73K | 14.6K |
| HotpotQA | qa | 74K | 14.8K |
| HumanEval | code | 137 | 27 |
| MBPP | code | 356 | 71 |
| **Total** | - | **160K** | **32K** |

After mixing: `train_mixed.jsonl` = 160K samples (Math 40% + QA 30% + Code 30%)

---

## ğŸ’¡ Usage Examples

### Change Training Parameters
```bash
# Edit config/training.yaml, then:
python train.py --config config/training.yaml --model qwen25-7b
```

### Use Different Model
```bash
./scripts/run_full_pipeline.sh --model qwen3-8b --device cuda:1
```

### Skip Data Processing
```bash
./scripts/run_full_pipeline.sh --skip-download --skip-process
```

### Evaluation Only
```bash
python scripts/eval_6datasets.py \
  --model qwen25-7b \
  --checkpoint checkpoints/qwen25-7b/grpo_mixed/step_100
```

---

## ğŸ” Project Structure

```
llm-as-judge/
â”œâ”€â”€ README.md                        # Overview (this file)
â”œâ”€â”€ SETUP.md                         # Installation guide
â”œâ”€â”€ DATA.md                          # Data strategy & format
â”œâ”€â”€ TRAINING.md                      # Training configs
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_datasets.py        # Download from HuggingFace
â”‚   â”œâ”€â”€ process_datasets.py         # Unify & mix (5:1, 50:50, 4:3:3)
â”‚   â”œâ”€â”€ eval_6datasets.py           # Evaluate all 6 datasets
â”‚   â””â”€â”€ run_full_pipeline.sh        # Automation script
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ grpo_trainer.py             # Main training loop
â”‚   â”œâ”€â”€ data_manager.py             # Mixed data sampling
â”‚   â”œâ”€â”€ reward_computer.py          # LLM judge + metrics
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ training.yaml               # Training hyperparameters
â”‚   â”œâ”€â”€ models.yaml                 # Model definitions
â”‚   â””â”€â”€ dataset.yaml                # Dataset metadata
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                        # Downloaded raw datasets
â”‚   â”œâ”€â”€ processed/                  # Per-dataset splits
â”‚   â”œâ”€â”€ mixed/                      # Mixed train/test
â”‚   â””â”€â”€ test/                       # Individual test sets
â”‚
â”œâ”€â”€ checkpoints/                    # Model checkpoints
â”‚   â”œâ”€â”€ qwen25-7b/grpo_mixed/
â”‚   â””â”€â”€ qwen3-8b/grpo_mixed/
â”‚
â””â”€â”€ results/evaluation/             # Results JSON
```

---

## â“ Troubleshooting

### CUDA Out of Memory
Reduce `rollout_batch_size` in `config/training.yaml`:
```yaml
rollout_batch_size: 2  # Default: 4
```

### Model Download Fails
Download manually:
```bash
huggingface-cli download Qwen/Qwen2.5-7B-Instruct \
  --local-dir ./models/Qwen2.5-7B-Instruct
```

### Data Processing Errors
Check log output and verify HuggingFace connectivity:
```bash
python -c "from datasets import load_dataset; print('âœ“ Datasets lib OK')"
```

For more help â†’ see [SETUP.md](SETUP.md) or [TRAINING.md](TRAINING.md)

---

## ğŸ“– Next Steps

1. Read [SETUP.md](SETUP.md) for detailed installation
2. Review [DATA.md](DATA.md) to understand data mixing
3. Check [TRAINING.md](TRAINING.md) for training specifics
4. Run `./scripts/run_full_pipeline.sh --model qwen25-7b` for end-to-end test

---

<div align="center">

**Built for reproducible baseline experiments with mixed-domain training**

Questions? Check the docs â†’ [SETUP](SETUP.md) | [DATA](DATA.md) | [TRAINING](TRAINING.md)

</div>
