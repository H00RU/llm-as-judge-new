#!/usr/bin/env python3
"""
ä¸‹è½½æ‰€æœ‰6ä¸ªæ•°æ®é›†
"""
import os
from pathlib import Path
from datasets import load_dataset
import json

class DatasetDownloader:
    """æ•°æ®é›†ä¸‹è½½å™¨"""

    def __init__(self, output_dir="data/raw"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºå­ç›®å½•
        (self.output_dir / "math").mkdir(exist_ok=True)
        (self.output_dir / "qa").mkdir(exist_ok=True)
        (self.output_dir / "code").mkdir(exist_ok=True)

    def download_gsm8k(self):
        """ä¸‹è½½GSM8K"""
        print("\nğŸ“¥ ä¸‹è½½ GSM8K...")
        try:
            dataset = load_dataset("openai/gsm8k", "main")

            # ä¿å­˜ä¸ºjsonl
            output_path = self.output_dir / "math" / "gsm8k.jsonl"
            with open(output_path, "w") as f:
                for item in dataset["train"]:
                    f.write(json.dumps(item) + "\n")

            print(f"  âœ… GSM8K: {len(dataset['train'])} samples")
            return len(dataset['train'])
        except Exception as e:
            print(f"  âŒ GSM8K ä¸‹è½½å¤±è´¥: {e}")
            return 0

    def download_math(self):
        """ä¸‹è½½MATH"""
        print("\nğŸ“¥ ä¸‹è½½ MATH...")
        try:
            # ä½¿ç”¨qwedsacfé•œåƒï¼ˆåŸå§‹hendrycks/competition_mathä¸å¯ç”¨ï¼‰
            dataset = load_dataset("qwedsacf/competition_math")

            if "train" in dataset:
                data = dataset["train"]
            else:
                available_splits = list(dataset.keys())
                data = dataset[available_splits[0]]

            output_path = self.output_dir / "math" / "math.jsonl"
            with open(output_path, "w") as f:
                for item in data:
                    f.write(json.dumps(item) + "\n")

            print(f"  âœ… MATH: {len(data)} samples")
            return len(data)
        except Exception as e:
            print(f"  âŒ MATH ä¸‹è½½å¤±è´¥: {e}")
            return 0

    def download_squad2(self):
        """ä¸‹è½½SQuAD 2.0"""
        print("\nğŸ“¥ ä¸‹è½½ SQuAD 2.0...")
        try:
            dataset = load_dataset("rajpurkar/squad_v2")

            output_path = self.output_dir / "qa" / "squad2.jsonl"
            with open(output_path, "w") as f:
                for item in dataset["train"]:
                    f.write(json.dumps(item) + "\n")

            print(f"  âœ… SQuAD 2.0: {len(dataset['train'])} samples")
            return len(dataset['train'])
        except Exception as e:
            print(f"  âŒ SQuAD 2.0 ä¸‹è½½å¤±è´¥: {e}")
            return 0

    def download_hotpotqa(self):
        """ä¸‹è½½HotpotQA"""
        print("\nğŸ“¥ ä¸‹è½½ HotpotQA...")
        try:
            dataset = load_dataset("hotpotqa/hotpot_qa", "fullwiki")

            output_path = self.output_dir / "qa" / "hotpotqa.jsonl"
            with open(output_path, "w") as f:
                for item in dataset["train"]:
                    f.write(json.dumps(item) + "\n")

            print(f"  âœ… HotpotQA: {len(dataset['train'])} samples")
            return len(dataset['train'])
        except Exception as e:
            print(f"  âŒ HotpotQA ä¸‹è½½å¤±è´¥: {e}")
            return 0

    def download_humaneval(self):
        """ä¸‹è½½HumanEval"""
        print("\nğŸ“¥ ä¸‹è½½ HumanEval...")
        try:
            dataset = load_dataset("openai/openai_humaneval")

            output_path = self.output_dir / "code" / "humaneval.jsonl"
            with open(output_path, "w") as f:
                for item in dataset["test"]:
                    f.write(json.dumps(item) + "\n")

            print(f"  âœ… HumanEval: {len(dataset['test'])} samples")
            return len(dataset['test'])
        except Exception as e:
            print(f"  âŒ HumanEval ä¸‹è½½å¤±è´¥: {e}")
            return 0

    def download_mbpp(self):
        """ä¸‹è½½MBPP"""
        print("\nğŸ“¥ ä¸‹è½½ MBPP...")
        try:
            dataset = load_dataset("google-research-datasets/mbpp", "full")

            output_path = self.output_dir / "code" / "mbpp.jsonl"
            with open(output_path, "w") as f:
                for item in dataset["train"]:
                    f.write(json.dumps(item) + "\n")

            print(f"  âœ… MBPP: {len(dataset['train'])} samples")
            return len(dataset['train'])
        except Exception as e:
            print(f"  âŒ MBPP ä¸‹è½½å¤±è´¥: {e}")
            return 0

    def run_all(self):
        """ä¸‹è½½æ‰€æœ‰æ•°æ®é›†"""
        print("=" * 60)
        print("å¼€å§‹ä¸‹è½½6ä¸ªæ•°æ®é›†...")
        print("=" * 60)

        stats = {
            "gsm8k": self.download_gsm8k(),
            "math": self.download_math(),
            "squad2": self.download_squad2(),
            "hotpotqa": self.download_hotpotqa(),
            "humaneval": self.download_humaneval(),
            "mbpp": self.download_mbpp(),
        }

        total = sum(stats.values())
        print("\n" + "=" * 60)
        print(f"âœ… ä¸‹è½½å®Œæˆï¼æ€»è®¡: {total} æ ·æœ¬")
        print("=" * 60)
        print("\næ•°æ®ç»Ÿè®¡:")
        for dataset, count in stats.items():
            print(f"  {dataset}: {count} samples")

        # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯
        with open(self.output_dir / "download_stats.json", "w") as f:
            json.dump(stats, f, indent=2)

if __name__ == "__main__":
    downloader = DatasetDownloader()
    downloader.run_all()
