#!/usr/bin/env python3
"""
å·¥ä½œæµä»£ç æ„å»ºå™¨ - ä»Qwenè¾“å‡ºä¸­å®Œæ•´é‡æ„å·¥ä½œæµä»£ç 

æ›¿ä»£æ—§çš„å¤šå±‚è¡¥æ•‘ç³»ç»Ÿï¼Œé‡‡ç”¨å®Œæ•´é‡æ„çš„æ–¹å¼ç¡®ä¿å…¨å±€ä¸€è‡´æ€§
"""
import re
import ast
from typing import Set, Optional, Tuple, Dict
from src.workflow_consistency_checker import WorkflowConsistencyChecker


class WorkflowCodeBuilder:
    """
    ä»Qwençš„è‡ªç„¶è¯­è¨€è¾“å‡ºä¸­é‡æ„å®Œæ•´çš„ã€ä¸€è‡´çš„å·¥ä½œæµä»£ç 

    è®¾è®¡åŸåˆ™ï¼š
    - ä¸ä¿¡ä»»Qwenç”Ÿæˆçš„import/initï¼Œè‡ªåŠ¨å®Œæ•´é‡æ„
    - è‡ªåŠ¨æ£€æµ‹__call__ä¸­ä½¿ç”¨çš„operator
    - è‡ªåŠ¨ç”Ÿæˆå®Œæ•´çš„importå’Œåˆå§‹åŒ–
    - æœ€ç»ˆéªŒè¯å…¨å±€ä¸€è‡´æ€§
    """

    def __init__(self):
        """åˆå§‹åŒ–ä»£ç æ„å»ºå™¨"""
        self.checker = WorkflowConsistencyChecker()
        self.valid_operators = {
            'Custom', 'AnswerGenerate', 'Programmer', 'Test',
            'Review', 'Revise', 'ScEnsemble'
        }

    def build_from_qwen_output(
        self,
        qwen_text: str,
        problem_type: str = "math",
        strict: bool = True
    ) -> Tuple[str, bool, Optional[str]]:
        """
        ä»Qwençš„è¾“å‡ºä¸­é‡æ„å®Œæ•´çš„å·¥ä½œæµä»£ç 

        æ­¥éª¤:
        1. æå–__call__æ–¹æ³•çš„é€»è¾‘éƒ¨åˆ†
        2. è‡ªåŠ¨åˆ†æ__call__ä¸­ä½¿ç”¨äº†å“ªäº›operator
        3. è‡ªåŠ¨ç”Ÿæˆå®Œæ•´çš„importè¯­å¥
        4. è‡ªåŠ¨ç”Ÿæˆå®Œæ•´çš„operatoråˆå§‹åŒ–
        5. æ‹¼æ¥æˆå®Œæ•´çš„ä»£ç 
        6. éªŒè¯ä¸€è‡´æ€§

        Args:
            qwen_text: Qwenæ¨¡å‹çš„è¾“å‡ºæ–‡æœ¬
            problem_type: é—®é¢˜ç±»å‹ ("math", "code", "qa")
            strict: æ˜¯å¦ä¸¥æ ¼æ¨¡å¼ï¼ˆå¤±è´¥æ—¶æŠ›å¼‚å¸¸ï¼‰

        Returns:
            (code, success, error_msg)
            - code: é‡æ„åçš„å®Œæ•´ä»£ç 
            - success: æ˜¯å¦é‡æ„æˆåŠŸ
            - error_msg: é”™è¯¯ä¿¡æ¯ï¼ˆå¦‚æœå¤±è´¥ï¼‰
        """
        try:
            # Step 1: æå–__call__é€»è¾‘
            call_logic, call_signature = self._extract_call_logic(qwen_text, problem_type)
            if not call_logic:
                raise ValueError("æ— æ³•ä»è¾“å‡ºä¸­æå–__call__æ–¹æ³•")

            # Step 2: æ£€æµ‹operatorä½¿ç”¨
            used_operators = self._detect_used_operators(call_logic)
            if not used_operators:
                # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°operatorï¼Œä½¿ç”¨Customä½œä¸ºé»˜è®¤
                used_operators = {'custom': 'Custom'}

            # Step 3: ç”Ÿæˆimport
            imports = self._generate_imports(used_operators)

            # Step 4: ç”Ÿæˆåˆå§‹åŒ–
            inits = self._generate_initializations(used_operators)

            # Step 5: æ‹¼æ¥å®Œæ•´ä»£ç 
            full_code = self._assemble_workflow(
                imports=imports,
                inits=inits,
                call_signature=call_signature,
                call_logic=call_logic,
                problem_type=problem_type
            )

            # Step 6: éªŒè¯ä¸€è‡´æ€§
            result = self.checker.check_consistency(full_code)
            if not result['consistent']:
                if strict:
                    raise ValueError(f"ä»£ç ä»ä¸ä¸€è‡´: {result['issues']}")
                else:
                    print(f"âš ï¸ è­¦å‘Š: ä»£ç ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥ä½†ç»§ç»­")
                    print(f"   é—®é¢˜: {result['issues']}")

            return full_code, True, None

        except Exception as e:
            error_msg = f"ä»£ç é‡æ„å¤±è´¥: {str(e)}"
            if strict:
                raise
            return "", False, error_msg

    def _extract_call_logic(
        self,
        qwen_text: str,
        problem_type: str
    ) -> Tuple[str, str]:
        """
        ä»Qwenè¾“å‡ºä¸­æå–__call__æ–¹æ³•çš„å®ç°é€»è¾‘

        è¿”å›: (call_logic_code, call_signature)
        """
        # âœ… CRITICAL FIX: Normalize indentation FIRST (fixes 60-70% of errors)
        qwen_text = self._normalize_indentation(qwen_text)

        # æŸ¥æ‰¾ async def __call__
        pattern = r'async\s+def\s+__call__\s*\(([^)]+)\)\s*:'
        match = re.search(pattern, qwen_text)

        if not match:
            # ä½¿ç”¨é»˜è®¤signature
            if problem_type == "code":
                call_signature = "async def __call__(self, problem: str, entry_point: str, test: str):"
            else:
                call_signature = "async def __call__(self, problem: str):"
            # å°è¯•æå–æ–¹æ³•ä½“
            body_pattern = r'(?:async\s+)?def\s+__call__[^:]*:\s*([\s\S]+?)(?=\n\s{0,4}(?:def|class|\Z))'
            body_match = re.search(body_pattern, qwen_text)
            if body_match:
                body = body_match.group(1).strip()
            else:
                # å¦‚æœå®Œå…¨æ‰¾ä¸åˆ°ï¼Œè¿”å›é»˜è®¤å®ç°
                body = "pass"
        else:
            # æå–å®Œæ•´çš„call_signature
            params = match.group(1)
            call_signature = f"async def __call__(self, {params}):"

            # æå–__call__æ–¹æ³•ä½“
            # æ‰¾åˆ°__call__å®šä¹‰åï¼Œæå–åˆ°ä¸‹ä¸€ä¸ªæ–¹æ³•æˆ–ç±»å®šä¹‰
            call_start = match.start()
            # ä»__call__ä¹‹åæŸ¥æ‰¾å†…å®¹
            content_after = qwen_text[call_start + len(match.group(0)):]
            body_end_match = re.search(r'\n(?=\s{0,4}(?:async\s+)?def\s+\w+|\s{0,4}class\s+|\Z)', content_after)

            if body_end_match:
                body = content_after[:body_end_match.start()].strip()
            else:
                body = content_after.strip()

        # æ¸…ç†bodyä¸­çš„ç¼©è¿› (use normalization instead of dedent)
        body = self._normalize_indentation(body)

        return body, call_signature

    def _detect_used_operators(self, call_logic: str) -> Dict[str, str]:
        """
        åˆ†æcall_logicä¸­ä½¿ç”¨äº†å“ªäº›operator

        è¿”å›: Dict[attribute_name -> class_name]
        ä¾‹å¦‚: {'answer_generate': 'AnswerGenerate', 'test': 'Test'}
        """
        used_operators = {}

        # æ¨¡å¼: await self.xxx(...)
        patterns = re.findall(r'await\s+self\.(\w+)\s*\(', call_logic)

        for attr_name in set(patterns):
            # æ¨æ–­operatorç±»å
            class_name = self._infer_operator_class(attr_name)
            if class_name:
                used_operators[attr_name] = class_name

        return used_operators

    def _infer_operator_class(self, attr_name: str) -> Optional[str]:
        """
        ä»operatorå±æ€§åæ¨æ–­ç±»å

        è§„åˆ™:
        - answer_generate -> AnswerGenerate
        - programmer -> Programmer
        - review -> Review
        - etc.
        """
        # ç›´æ¥æ˜ å°„
        mapping = {
            'custom': 'Custom',
            'answer_generate': 'AnswerGenerate',
            'programmer': 'Programmer',
            'test': 'Test',
            'review': 'Review',
            'revise': 'Revise',
            'sc_ensemble': 'ScEnsemble',
        }

        if attr_name in mapping:
            return mapping[attr_name]

        # å°è¯•é©¼å³°è½¬æ¢
        class_name = ''.join(word.capitalize() for word in attr_name.split('_'))
        if class_name in self.valid_operators:
            return class_name

        return None

    def _generate_imports(self, used_operators: Dict[str, str]) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„importè¯­å¥

        Args:
            used_operators: {attr_name -> class_name}

        Returns:
            å¯¼å…¥ä»£ç å­—ç¬¦ä¸²
        """
        # æ”¶é›†æ‰€æœ‰ä½¿ç”¨çš„ç±»å
        class_names = sorted(set(used_operators.values()))

        # ç”Ÿæˆimportè¯­å¥
        if class_names:
            imports_line = f"from scripts.operators import {', '.join(class_names)}"
        else:
            # è‡³å°‘å¯¼å…¥Customä½œä¸ºå¤‡é€‰
            imports_line = "from scripts.operators import Custom"

        return f"""{imports_line}
from scripts.async_llm import create_llm_instance
from scripts.evaluator import DatasetType"""

    def _generate_initializations(self, used_operators: Dict[str, str]) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„operatoråˆå§‹åŒ–ä»£ç 

        Args:
            used_operators: {attr_name -> class_name}

        Returns:
            åˆå§‹åŒ–ä»£ç ï¼ˆæ¯è¡Œç¼©è¿›ï¼‰
        """
        if not used_operators:
            return ""

        init_lines = []
        for attr_name, class_name in sorted(used_operators.items()):
            init_lines.append(f"        self.{attr_name} = {class_name}(self.llm)")

        return "\n".join(init_lines)

    def _assemble_workflow(
        self,
        imports: str,
        inits: str,
        call_signature: str,
        call_logic: str,
        problem_type: str
    ) -> str:
        """
        æ‹¼æ¥æˆå®Œæ•´çš„å·¥ä½œæµä»£ç 

        Args:
            imports: importè¯­å¥
            inits: operatoråˆå§‹åŒ–è¯­å¥
            call_signature: __call__æ–¹æ³•ç­¾å
            call_logic: __call__æ–¹æ³•ä½“
            problem_type: é—®é¢˜ç±»å‹

        Returns:
            å®Œæ•´çš„Pythonä»£ç 
        """
        # ç¡®ä¿call_logicæœ‰æ­£ç¡®çš„ç¼©è¿›
        call_logic_indented = self._indent_code(call_logic, 2)

        code = f"""{imports}

class Workflow:
    def __init__(self, name: str, llm_config, dataset: DatasetType):
        self.name = name
        self.dataset = dataset
        self.llm = create_llm_instance(llm_config)
{inits if inits else '        pass'}

    {call_signature}
{call_logic_indented}"""

        return code

    @staticmethod
    def _dedent_code(code: str) -> str:
        """
        ç§»é™¤ä»£ç çš„å…±åŒå‰å¯¼ç©ºæ ¼

        Args:
            code: åŸå§‹ä»£ç 

        Returns:
            å»é™¤ç¼©è¿›åçš„ä»£ç 
        """
        lines = code.split('\n')
        # æ‰¾åˆ°æœ€å°ç¼©è¿›
        non_empty_lines = [line for line in lines if line.strip()]
        if not non_empty_lines:
            return code

        min_indent = min(len(line) - len(line.lstrip()) for line in non_empty_lines)
        # ç§»é™¤æœ€å°ç¼©è¿›
        dedented = '\n'.join(
            line[min_indent:] if len(line) > min_indent else line
            for line in lines
        )
        return dedented.strip()

    @staticmethod
    def _normalize_indentation(code: str) -> str:
        """
        Normalize mixed tabs/spaces and remove common indentation prefix.

        This fixes ~60-70% of Python syntax errors caused by:
        - Mixed tabs and spaces
        - Inconsistent indentation levels
        - Extra leading whitespace

        Args:
            code: Original code string

        Returns:
            Normalized code with consistent spacing
        """
        lines = code.split('\n')

        # Step 1: Convert all tabs to 4 spaces
        normalized_lines = []
        for line in lines:
            # Replace each tab with 4 spaces
            normalized_line = line.replace('\t', '    ')
            # Also strip trailing whitespace
            normalized_line = normalized_line.rstrip()
            normalized_lines.append(normalized_line)

        # Step 2: Find minimum indentation level
        non_empty_lines = [line for line in normalized_lines if line.strip()]
        if not non_empty_lines:
            return code

        min_indent = min(len(line) - len(line.lstrip(' ')) for line in non_empty_lines)

        # Step 3: Remove common indentation prefix
        dedented_lines = []
        for line in normalized_lines:
            if len(line) >= min_indent:
                dedented_lines.append(line[min_indent:])
            else:
                dedented_lines.append(line)

        return '\n'.join(dedented_lines)

    @staticmethod
    def _indent_code(code: str, indent_level: int = 2) -> str:
        """
        ä¸ºä»£ç æ·»åŠ ç¼©è¿›

        Args:
            code: åŸå§‹ä»£ç 
            indent_level: ç¼©è¿›çº§åˆ«ï¼ˆç©ºæ ¼æ•°ï¼‰

        Returns:
            ç¼©è¿›åçš„ä»£ç 
        """
        indent = ' ' * indent_level
        lines = code.split('\n')
        indented_lines = []

        for line in lines:
            if line.strip():  # éç©ºè¡Œ
                indented_lines.append(indent + line)
            else:  # ç©ºè¡Œä¿æŒç©º
                indented_lines.append('')

        return '\n'.join(indented_lines)

    def validate(self, code: str, verbose: bool = False) -> Tuple[bool, Optional[str]]:
        """
        éªŒè¯ä»£ç çš„ä¸€è‡´æ€§å’Œè¯­æ³•

        Args:
            code: Pythonä»£ç 
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            (is_valid, error_message)
        """
        # è¯­æ³•éªŒè¯
        try:
            ast.parse(code)
        except SyntaxError as e:
            return False, f"è¯­æ³•é”™è¯¯: {str(e)}"

        # ä¸€è‡´æ€§éªŒè¯
        result = self.checker.check_consistency(code)
        if not result['consistent']:
            error_msg = "; ".join(result['issues'])
            return False, f"ä¸€è‡´æ€§æ£€æŸ¥å¤±è´¥: {error_msg}"

        if verbose:
            print(self.checker.get_summary(result))

        return True, None


# æµ‹è¯•å‡½æ•°
def test_builder():
    """æµ‹è¯•å·¥ä½œæµä»£ç æ„å»ºå™¨"""
    builder = WorkflowCodeBuilder()

    # æµ‹è¯•è¾“å…¥: Qwenç”Ÿæˆçš„ç‰‡æ®µè¾“å‡º
    qwen_output = """
async def __call__(self, problem: str):
    # ä½¿ç”¨answer_generateæ¥è§£å†³é—®é¢˜
    result = await self.answer_generate(input=problem)
    answer = result.get('answer', '')

    # å¦‚æœéœ€è¦éªŒè¯
    review = await self.review(problem=problem, solution=answer)

    # è¿”å›ç­”æ¡ˆ
    return answer, self.llm.get_usage_summary()["total_cost"]
"""

    print("\nğŸ”¨ æµ‹è¯•ä»£ç æ„å»ºå™¨")
    print("=" * 70)

    code, success, error = builder.build_from_qwen_output(qwen_output, problem_type="math", strict=False)

    if success:
        print("âœ… ä»£ç é‡æ„æˆåŠŸ!")
        print("\nğŸ“„ é‡æ„åçš„ä»£ç :")
        print(code)

        # éªŒè¯
        is_valid, val_error = builder.validate(code, verbose=True)
        if is_valid:
            print("\nâœ… ä»£ç éªŒè¯é€šè¿‡!")
        else:
            print(f"\nâŒ ä»£ç éªŒè¯å¤±è´¥: {val_error}")
    else:
        print(f"âŒ ä»£ç é‡æ„å¤±è´¥: {error}")


if __name__ == "__main__":
    test_builder()
