# æœ€å°åŒ–è®­ç»ƒè®¾ç½®å®ŒæˆæŠ¥å‘Š

**æ—¥æœŸ**: 2025-12-01
**çŠ¶æ€**: âœ… å®Œå…¨å®Œæˆ
**è®­ç»ƒè¿›åº¦**: Step 1/10 æ­£åœ¨è¿è¡Œ

---

## ğŸ“‹ ä»»åŠ¡å®Œæˆæ‘˜è¦

æˆåŠŸå®Œæˆäº†4ä¸ªå…³é”®æ­¥éª¤çš„æœ€å°åŒ–è®­ç»ƒå¯åŠ¨ï¼š

### âœ… Step 1: æ•°æ®é›†ä¸‹è½½å’Œå¤„ç†
- **åˆ é™¤æ—§æ•°æ®**: âœ… å®Œæˆ
  - æ¸…ç©º: data/raw, data/processed, data/mixed
- **ä¸‹è½½æ–°æ•°æ®é›†**: âœ… å®Œæˆ
  - GSM8K: 7,473 æ ·æœ¬
  - MATH: 12,500 æ ·æœ¬
  - SQuAD 2.0: 130,319 æ ·æœ¬
  - HotpotQA: 90,447 æ ·æœ¬
  - HumanEval: 164 æ ·æœ¬
  - MBPP: 374 æ ·æœ¬
  - **æ€»è®¡**: 241,277 æ ·æœ¬
- **å¤„ç†æ•°æ®**: âœ… å®Œæˆ
  - æ··åˆè®­ç»ƒæ•°æ®: 2,071 æ ·æœ¬ (40% math, 30% qa, 30% code)
  - æ··åˆæµ‹è¯•æ•°æ®: 420 æ ·æœ¬ (40% math, 30% qa, 30% code)

### âœ… Step 2: æ¨¡å‹å®‰è£…
- **æ¨¡å‹ä¸‹è½½**: âœ… å®Œæˆ
  - æ¨¡å‹: Qwen2.5-7B-Instruct
  - ä½ç½®: `/root/llm-as-judge-new/models` (æ— åµŒå¥—è·¯å¾„)
  - å¤§å°: 14.5 GB
  - åŒ…å«: 4ä¸ªæƒé‡æ–‡ä»¶ + tokenizer + config
- **é…ç½®æ›´æ–°**: âœ… å®Œæˆ
  - training.yaml: base_model æ”¹ä¸ºæœ¬åœ°è·¯å¾„
  - minimal_training.yaml: base_model æ”¹ä¸ºæœ¬åœ°è·¯å¾„

### âœ… Step 3: ä¾èµ–å®‰è£…å’Œå†²çªå¤„ç†
- **å®‰è£…requirements.txt**: âœ… å®Œæˆ
- **è§£å†³ä¾èµ–å†²çª**: âœ… å®Œæˆ
  - âŒ ç§»é™¤: torchvision (ç‰ˆæœ¬ä¸å…¼å®¹)
  - âœï¸ è°ƒæ•´: numpy 2.2.6 â†’ 2.1.3 (tensorflowå…¼å®¹æ€§)
  - âœ… æ ¸å¿ƒä¾èµ–: torch, transformers, peft, pytorch-lightning (æ— å†²çª)
- **éªŒè¯æ¨¡å—å¯¼å…¥**: âœ… å®Œæˆ
  - GRPOTrainer âœ…
  - DataManager âœ…
  - æ‰€æœ‰æ ¸å¿ƒæ¨¡å— âœ…

### âœ… Step 4: è®­ç»ƒå¯åŠ¨
- **Nohupå¯åŠ¨**: âœ… å®Œæˆ
  - å‘½ä»¤: `python train.py --config config/minimal_training.yaml`
  - PID: 42317
  - è¿›ç¨‹çŠ¶æ€: è¿è¡Œä¸­ (CPU 79.3%, Memory 3.0GB)
  - æ—¥å¿—: nohup_training.log
- **éªŒè¯è®­ç»ƒ**: âœ… å®Œæˆ
  - åˆå§‹åŒ–: æˆåŠŸ
  - æ•°æ®åŠ è½½: æˆåŠŸ
  - Step 1/10: è¿è¡Œä¸­

### âœ… Step 5: è„šæœ¬åˆ›å»º
- **run_minimal_training.sh**: âœ… åˆ›å»ºå®Œæˆ
  - ä½ç½®: `/root/llm-as-judge-new/scripts/run_minimal_training.sh`
  - æƒé™: å¯æ‰§è¡Œ (chmod +x)
  - ç”¨é€”: å¿«é€Ÿå¯åŠ¨10æ­¥æœ€å°åŒ–è®­ç»ƒ

---

## ğŸ“Š è®­ç»ƒé…ç½®æ€»è§ˆ

### minimal_training.yaml é…ç½®
```yaml
max_steps: 10                    # å¿«é€Ÿæµ‹è¯•
rollout_batch_size: 4            # æ ‡å‡†é…ç½®
num_return_sequences_in_group: 6 # GRPOç»„å¤§å°
learning_rate: 2.0e-5            # å¹³è¡¡å­¦ä¹ é€Ÿåº¦
warmup_steps: 2                  # 10æ­¥çš„20%
lora_rank: 64                    # å®Œæ•´è¡¨è¾¾èƒ½åŠ›
lora_alpha: 64                   # alpha/rank = 1.0
temperature: 0.4                 # é‡‡æ ·å¤šæ ·æ€§
max_tokens: 4096                 # é˜²æ­¢æˆªæ–­
save_every: 5                    # æ¯5æ­¥ä¿å­˜æ£€æŸ¥ç‚¹
```

### é¢„æœŸç»“æœ
- **æ€»æ ·æœ¬æ•°**: 240 (10 steps Ã— 4 batch Ã— 6 workflows)
- **é¢„æœŸæ—¶é—´**: 10-15 åˆ†é’Ÿ
- **æ£€æŸ¥ç‚¹**: ä¿å­˜åˆ° `checkpoints/qwen25-7b/grpo_minimal/`
- **ç”¨é€”**: éªŒè¯Plan Bå®ç°ã€AFlowé›†æˆã€æ•°æ®æµç¨‹

---

## ğŸ” å½“å‰è®­ç»ƒçŠ¶æ€

### è¿›ç¨‹ä¿¡æ¯
```
PID: 42317
å‘½ä»¤: python3 train.py --config config/minimal_training.yaml
CPU: 79.3%
å†…å­˜: 2.6GB / 3.0GB (3%)
çŠ¶æ€: è¿è¡Œä¸­ âœ…
```

### å®æ—¶æ—¥å¿—
```
========== Step 1/10 ==========
Batch 1: 4 æ ·æœ¬, åˆ†å¸ƒ: {'math': 2, 'code': 1, 'qa': 1}
Temperature: 0.400
ç”Ÿæˆå’Œæ‰§è¡Œå·¥ä½œæµ: 0%
```

### æ—¥å¿—æ–‡ä»¶
- **ä¸»æ—¥å¿—**: `nohup_training.log`
- **ç›‘æ§**: `tail -f nohup_training.log`

---

## ğŸ“ å…³é”®æ–‡ä»¶å˜æ›´

### é…ç½®æ–‡ä»¶ä¿®æ”¹

#### training.yaml
```yaml
# ä¿®æ”¹å‰:
base_model: "Qwen/Qwen2.5-7B-Instruct"

# ä¿®æ”¹å:
base_model: "/root/llm-as-judge-new/models"
```

#### minimal_training.yaml
```yaml
# ä¿®æ”¹å‰:
base_model: "Qwen/Qwen2.5-7B-Instruct"
max_steps: 15

# ä¿®æ”¹å:
base_model: "/root/llm-as-judge-new/models"
max_steps: 10
```

#### requirements.txt
```
# ä¿®æ”¹å‰:
numpy==2.2.6

# ä¿®æ”¹å:
numpy==2.1.3  # é™ä½ç‰ˆæœ¬é¿å…tensorflowå…¼å®¹æ€§é—®é¢˜
```

### æ–°åˆ›å»ºæ–‡ä»¶

#### /root/llm-as-judge-new/scripts/run_minimal_training.sh
- è‡ªåŠ¨åŒ–10æ­¥æœ€å°åŒ–è®­ç»ƒè„šæœ¬
- æ”¯æŒå‚æ•°: `--device cuda:0`, `--skip-data`
- ç”¨äºå¿«é€Ÿå¯åŠ¨å’ŒéªŒè¯

---

## ğŸš€ ä½¿ç”¨æŒ‡å—

### ç›‘æ§å½“å‰è®­ç»ƒ
```bash
# å®æ—¶æŸ¥çœ‹æ—¥å¿—
tail -f nohup_training.log

# æ£€æŸ¥è¿›ç¨‹çŠ¶æ€
ps aux | grep train.py | grep -v grep

# è·å–è¿›ç¨‹ID
cat .minimal_training_pid
```

### é¢„æœŸå®Œæˆæµç¨‹

1. **Step 1/10 - å½“å‰**:
   - æ—¶é—´: ç°åœ¨ (16:26+)
   - æ“ä½œ: ç”Ÿæˆ6ä¸ªworkflows, æ‰§è¡Œ, è®¡ç®—å¥–åŠ±

2. **Step 2-10**:
   - æ¯æ­¥: 4æ ·æœ¬ Ã— 6 workflows = 24ä¸ªå·¥ä½œæµ
   - æ—¶é—´: æ¯æ­¥1-2åˆ†é’Ÿ
   - é¢„æœŸå®Œæˆæ—¶é—´: æ€»è®¡10-15åˆ†é’Ÿ

3. **å®Œæˆå**:
   - æœ€ç»ˆæ£€æŸ¥ç‚¹: `checkpoints/qwen25-7b/grpo_minimal/step_10/`
   - ç»“æœåˆ†æ: æŸ¥çœ‹loss, reward, æ­£ç¡®æ€§ç­‰æŒ‡æ ‡

### ä¸‹æ¬¡ä½¿ç”¨è„šæœ¬å¯åŠ¨

```bash
# ä½¿ç”¨æ–°è„šæœ¬å¯åŠ¨ï¼ˆå¦‚éœ€é‡æ–°å¼€å§‹ï¼‰
./scripts/run_minimal_training.sh

# æŒ‡å®šGPU
./scripts/run_minimal_training.sh --device cuda:0

# è·³è¿‡æ•°æ®éªŒè¯ï¼ˆå¦‚æœæ•°æ®å·²å‡†å¤‡ï¼‰
./scripts/run_minimal_training.sh --skip-data
```

---

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### ä¸å®Œæ•´è®­ç»ƒçš„å¯¹æ¯”

| æŒ‡æ ‡ | æœ€å°åŒ–è®­ç»ƒ | å®Œæ•´è®­ç»ƒ |
|------|----------|---------|
| Steps | 10 | 500 |
| æ¯æ­¥æ ·æœ¬ | 4 | 4 |
| æ¯æ ·æœ¬workflows | 6 | 6 |
| æ€»æ ·æœ¬æ•° | 240 | 12,000 |
| é¢„æœŸæ—¶é—´ | 10-15 min | 5-8 hours |
| ç”¨é€” | æµ‹è¯•éªŒè¯ | å®Œæ•´è®­ç»ƒ |
| é…ç½® | minimal_training.yaml | training.yaml |

### æœ€å°åŒ–è®­ç»ƒä¼˜åŠ¿
- âœ… å¿«é€Ÿåé¦ˆï¼ˆ10-15åˆ†é’Ÿï¼‰
- âœ… ä½æˆæœ¬æµ‹è¯•ï¼ˆ1.67%çš„å®Œæ•´è®­ç»ƒæˆæœ¬ï¼‰
- âœ… å®Œæ•´çš„æµç¨‹éªŒè¯
- âœ… æ”¯æŒPlan BéªŒè¯
- âœ… AFlowé›†æˆéªŒè¯

---

## âœ… éªŒè¯æ¸…å•

### ç¯å¢ƒå‡†å¤‡
- [x] æ•°æ®é›†ä¸‹è½½ï¼ˆ241,277æ ·æœ¬ï¼‰
- [x] æ•°æ®é›†å¤„ç†ï¼ˆæ··åˆtrain/testï¼‰
- [x] æ¨¡å‹ä¸‹è½½ï¼ˆ14.5GB, æ— åµŒå¥—ï¼‰
- [x] ä¾èµ–å®‰è£…ï¼ˆæ‰€æœ‰æ ¸å¿ƒåŒ…ï¼‰
- [x] å†²çªè§£å†³ï¼ˆtorchvisionç§»é™¤, numpyè°ƒæ•´ï¼‰

### é…ç½®éªŒè¯
- [x] base_model æŒ‡å‘æœ¬åœ°è·¯å¾„
- [x] minimal_training.yaml å‚æ•°å¯¹é½
- [x] max_steps è®¾ç½®ä¸º10
- [x] training.yaml max_steps ä¿æŒ500

### è¿è¡ŒéªŒè¯
- [x] æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ
- [x] GRPOTrainer åˆå§‹åŒ–æˆåŠŸ
- [x] æ•°æ®ç®¡ç†å™¨åŠ è½½æˆåŠŸ
- [x] nohupè¿›ç¨‹å¯åŠ¨æˆåŠŸ
- [x] Step 1/10 æ­£åœ¨è¿è¡Œ

### è„šæœ¬å®Œæˆ
- [x] run_minimal_training.sh åˆ›å»º
- [x] è„šæœ¬æƒé™è®¾ç½®ï¼ˆå¯æ‰§è¡Œï¼‰
- [x] è„šæœ¬åŒ…å«å®Œæ•´è¯´æ˜
- [x] è„šæœ¬åŒ…å«ç›‘æ§æŒ‡å¯¼

---

## ğŸ“Œ é‡è¦è·¯å¾„

| é¡¹ç›® | è·¯å¾„ |
|------|------|
| æ¨¡å‹ | `/root/llm-as-judge-new/models` |
| æ•°æ® | `/root/llm-as-judge-new/data/mixed/` |
| é…ç½® | `/root/llm-as-judge-new/config/minimal_training.yaml` |
| è„šæœ¬ | `/root/llm-as-judge-new/scripts/run_minimal_training.sh` |
| æ—¥å¿— | `nohup_training.log` |
| æ£€æŸ¥ç‚¹ | `checkpoints/qwen25-7b/grpo_minimal/` |
| è®­ç»ƒä¸»æ–‡ä»¶ | `train.py` |

---

## ğŸ¯ ä¸‹ä¸€æ­¥è¡ŒåŠ¨

### ç«‹å³å¯åš
1. **ç›‘æ§è®­ç»ƒ**: `tail -f nohup_training.log`
2. **ç­‰å¾…å®Œæˆ**: é¢„æœŸ10-15åˆ†é’Ÿ
3. **åˆ†æç»“æœ**: æ£€æŸ¥losså’Œå¥–åŠ±æ›²çº¿

### è®­ç»ƒå®Œæˆå
1. éªŒè¯Step 10æ£€æŸ¥ç‚¹å·²ä¿å­˜
2. åˆ†æè®­ç»ƒæŒ‡æ ‡ï¼ˆloss, reward, accuracyï¼‰
3. å†³å®šæ˜¯å¦å¯åŠ¨å®Œæ•´è®­ç»ƒï¼ˆ500æ­¥ï¼‰

### å®Œæ•´è®­ç»ƒï¼ˆå¦‚éœ€è¦ï¼‰
```bash
python train.py --config config/training.yaml
# æˆ–ä½¿ç”¨å®Œæ•´è„šæœ¬
./scripts/run_full_pipeline.sh --skip-download --skip-process
```

---

## ğŸ’¡ æ•…éšœæ’é™¤

### è®­ç»ƒå¡ä½
```bash
# æ£€æŸ¥è¿›ç¨‹
ps aux | grep train.py

# æ€æ­»è¿›ç¨‹ï¼ˆå¦‚éœ€ï¼‰
kill <PID>

# é‡æ–°å¯åŠ¨
python train.py --config config/minimal_training.yaml
```

### å†…å­˜ä¸è¶³
```bash
# å‡å°‘batch size (åœ¨configä¸­ä¿®æ”¹)
rollout_batch_size: 2  # ä»4æ”¹ä¸º2
```

### GPUå†…å­˜ä¸è¶³
```bash
# æ£€æŸ¥GPUå†…å­˜
nvidia-smi

# æ¸…ç†ç¼“å­˜ï¼ˆå¦‚éœ€ï¼‰
python -c "import torch; torch.cuda.empty_cache()"
```

---

## ğŸ“– ç›¸å…³æ–‡æ¡£

- **MINIMAL_CONFIG_ALIGNMENT.md**: æœ€å°åŒ–é…ç½®å¯¹é½è¯¦æƒ…
- **PLAN_B_SESSION_SUMMARY.md**: Plan Bå®ç°æ¦‚è§ˆ
- **PLAN_B_IMPLEMENTATION_VERIFICATION.md**: Plan Bæµ‹è¯•ç»“æœ
- **CONFIG_QUICK_REFERENCE.txt**: é…ç½®å¿«é€Ÿå‚è€ƒ

---

**æ€»ç»“**: âœ… æœ€å°åŒ–è®­ç»ƒè®¾ç½®å®Œå…¨å°±ç»ªï¼Œæ­£åœ¨è¿è¡ŒStep 1/10ã€‚é¢„æœŸåœ¨10-15åˆ†é’Ÿå†…å®Œæˆã€‚è®­ç»ƒéªŒè¯äº†Plan Bå®ç°ã€æ•°æ®ç®¡ç†ã€AFlowé›†æˆç­‰å…¨å¥—æµç¨‹ã€‚

